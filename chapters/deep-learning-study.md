# 🔬 ディープラーニングの研究分野

## 画像認識分野

##### [AlexNet (アレックスネット)](https://en.wikipedia.org/wiki/AlexNet)
2012年、ILSVRC で従来の SVM に替わりディープラーニングに基づくモデルで初めて優勝した。

筆頭開発者であるアレックス・クリジェフスキーの名前から、「アレックスネット」と呼ばれている。

### [R-CNN](https://ja.wikipedia.org/wiki/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)

![](https://media.geeksforgeeks.org/wp-content/uploads/20200219161502/RCNN1.png)
https://www.geeksforgeeks.org/r-cnn-vs-fast-r-cnn-vs-faster-r-cnn-ml/

##### R-CNN（Region Convolutional Neural Network）
空間認識にすぐれている CNN を分割された領域ごとに適用するディープニューラルネットワーク。

関心領域（ROI）の切り出しには、HOG など CNN ではない従来の手法を用いる。ROI の画像切り出しの後に領域ごとに個別に CNN を呼びだす二段階のモデルのため、時間がかかっていた。

画像上の矩形領域（長方形）、バウンディングボックスで、領域を切り出す。

##### fast RCNN
領域の切り出しと切り出した領域の物体認識を同時に行うモデル。

##### faster RCNN
fast RCNN を更に改良したモデル。
ほぼ実時間（1秒あたり16フレーム）で入力画像から関心領域の切り出しと認識がきるようになった。

##### YOLO (You Only Look Once)
領域の切り出しと認識を同時に行う CNN。

##### SSD (Single Shot Detector)
領域の切り出しと認識を同時に行う CNN。

### セマンティックセグメンテーション・インスタンスセグメンテーション

##### セマンティックセグメンテーション
R-CNN のような矩形領域を切り出すのではなく、より詳細な領域分割を得るモデル。
各画素がどのカテゴリーに属するかを求める手法。

同じカテゴリーに属する複数の物体が同一ラベルとして扱われる。

##### インスタンスセグメンテーション
個々の物体ごとにカテゴリーを認識させる。

##### FCN (完全畳み込みネットワーク)
セマンティックセグメンテーションを実現するネットワークモデル。

FCN とは文字通りすべての層が畳み込み層であるモデル。

入力画像の画素数だけ出力層が必要、つまり出力層には、縦画素数 x 横画素数 x カテゴリー数の出力ニューロンが用意される。

##### アンサンプリング
最終出力層で入力層と同じ解像度を得るために、下位層のプーリング層の情報を用いて詳細な解像度を得る手法。

CNN では畳み込み演算によって畳み込みのカーネル幅（受容野）だけ近傍の入力刺激を加えて計算することになるため、上位層では下位層にくらべて受容野が大きくなり、その影響で画像サイズは小さくなる。

##### Mask RCNN

## 自然言語処理

### 基本的なフロー

1. 形態素解析を用いて、文章を単語などの最小単位（形態素）に切り分ける
1. データのクレンジングにより、不要な文字列を取り除く
1. BoW（Bag-of-Words)などを用いて、形態素解析をおこなったデータをベクトル形式に変換する
1. TF-ID などを用いて、各単語の重要度を評価する

### 単語の意味を表すベクトル空間モデル

##### [word2vec](https://ja.wikipedia.org/wiki/Word2vec)
文章中の単語は、記号の集まりとして表現できる。この記号をベクトルとして表現することで、ベクトル間の距離や関係として単語の意味を表現するモデル。

Googleのトマス・ミコロフ率いる研究者チームによって2013年に作成された。

単語の意味をベクトル空間の中に表現したと考えられるため、「単語埋め込みモデル（word embedding models）」とも呼ばれる。

word2vec には以下の2つの手法がある。

##### スキップグラム（Skip-gram）
ある単語を与えて周辺の単語を予測するモデル。

##### CBOW
周辺の単語を与えてある単語を予測するモデル。

##### [セマンティックウェブ](https://ja.wikipedia.org/wiki/%E3%82%BB%E3%83%9E%E3%83%B3%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%83%BB%E3%82%A6%E3%82%A7%E3%83%96)
情報リソースに意味を付与することで、コンピュータで高度な意味処理を実現する

##### [意味ネットワーク](https://ja.wikipedia.org/wiki/%E6%84%8F%E5%91%B3%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
単語同士の意味関係をネットワークによって表現する

##### [統計的自然言語処理](https://ja.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86#%E7%B5%B1%E8%A8%88%E7%9A%84%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86)
言語処理に確率的あるいは統計的手法を用いる技術

##### [言語モデル](https://ja.wikipedia.org/wiki/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)
自然言語処理などにおいて、文の品詞や統語構造、単語と単語、文書と文書などの関係性について定式化したもの。

### 文章の意味表現

##### fastText
2013年に word2vec を提案したトマス・ミコロフらによって開発されたモデル。

word2vec との変更点は、単語の表現に文字情報も含めること。文字データを援用することで訓練データには存在しない単語（Out Of Vocabulary: OOV）を表現することを可能にした。

##### ELMo
[アレンインスティチュート](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%AC%E3%83%B3%E8%84%B3%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E6%89%80) によって開発された文章表現を得るモデル。

2層の双方向リカレントネットワーク言語モデルの内部状態から計算される。fastText と同じく OOV であっても意味表現を得ることが可能。

##### 普遍埋め込みモデル
1対多のマルチタスク学習により、複数課題間に共通の普遍的な文章埋め込み表現を学習するモデル。

##### [TF-IDF](https://ja.wikipedia.org/wiki/Tf-idf)
文書内に出現する単語について，以下の２つの情報から，その単語の重要度を算出する手法である．
- 単語の出現頻度 (TF値)
- 単語の逆文書頻度 (IDF値)

### その他の応用

##### NIC (ニューラル画像脚注付け)
画像認識をする CNN と言語モデルとしてのリカレントニューラルネットワークを組み合わせて、画像に脚注をつける手法。

##### NTM (ニューラルチューリングマシン)
チーリングマシンをニューラルネットワークで実現する試み。

## 音声認識

##### [WaveNet](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)
2016年に Google DeepMind 社により開発された、音声合成と音声認識の両者を行うことができるモデル。

サンプリングされた系列点としての音声をそのまま DNN を用いて処理することにより、近似や調整などという作業が不要になった。
自然な発音が実現されたため、音声合成のブレイクスルーとして注目されている。

##### [音声合成](https://ja.wikipedia.org/wiki/%E9%9F%B3%E5%A3%B0%E5%90%88%E6%88%90)
与えられた文やデータから人が話す音声を合成する技術。

近年劇的に発達し、人間が話しているものとほぼ同等に自然な音声を生成することが可能なレベルに達した。

## [強化学習](https://ja.wikipedia.org/wiki/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92)

##### [DQN (Deep Q-Network)](https://ja.wikipedia.org/wiki/DQN_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF))
DeepMind が考案した、Q学習の行動価値関数を、深い構造を持ったニューラルネットワークで置き換えたモデル。

##### [MCTS (モンテカルロ木探索)](https://ja.wikipedia.org/wiki/%E3%83%A2%E3%83%B3%E3%83%86%E3%82%AB%E3%83%AB%E3%83%AD%E6%9C%A8%E6%8E%A2%E7%B4%A2#%E3%83%A2%E3%83%B3%E3%83%86%E3%82%AB%E3%83%AB%E3%83%AD%E3%83%84%E3%83%AA%E3%83%BC%E6%A4%9C%E7%B4%A2_(MCTS))
モンテカルロ法を使った木の探索。

ヒューリスティクス（途中で不要な探索をやめ、ある程度の高確率で良い手を導ける）な探索アルゴリズムである。

##### [AlphaGo Zero](https://ja.wikipedia.org/wiki/AlphaGo_Zero)
2017年10月に発表された、棋譜を全く必要としない、完全に自己対局（セルフプレイ）のみで学習していく碁のプログラム。
従来の AlphaGo を超える強さとなった。
